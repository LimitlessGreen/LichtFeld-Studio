/* SPDX-FileCopyrightText: 2025 LichtFeld Studio Authors
 * SPDX-License-Identifier: GPL-3.0-or-later */

#include "core/tensor.hpp"
#include "core/tensor_ops.hpp"
#include <chrono>
#include <gtest/gtest.h>
#include <iomanip>
#include <iostream>

using namespace gs;
using namespace std::chrono;

class TransformIteratorBenchmarkTest : public ::testing::Test {
protected:
    void SetUp() override {
        Tensor::manual_seed(42);
    }

    struct BenchmarkResult {
        double eager_ms; // Materialize each intermediate result
        double lazy_ms;  // Single fused kernel (if optimized)
        double speedup;
        bool correctness_pass;
        size_t num_intermediates_saved; // How many allocations we avoid
    };

    // Benchmark: (x * scalar).sigmoid()  - Common pattern in neural nets
    BenchmarkResult benchmark_mul_sigmoid(size_t n, int num_iterations = 100) {
        auto data = Tensor::rand({static_cast<int>(n)}, Device::CUDA);
        float scalar = 2.0f;

        // Warm-up
        for (int i = 0; i < 5; ++i) {
            auto result = (data * scalar).sigmoid();
            cudaDeviceSynchronize();
        }

        // Benchmark eager evaluation (current default - materialize intermediates)
        auto start_eager = high_resolution_clock::now();
        Tensor result_eager;
        for (int i = 0; i < num_iterations; ++i) {
            auto temp = data * scalar;     // Allocate intermediate
            result_eager = temp.sigmoid(); // Allocate result
        }
        cudaDeviceSynchronize();
        auto end_eager = high_resolution_clock::now();
        double eager_ms = duration_cast<microseconds>(end_eager - start_eager).count() / 1000.0 / num_iterations;

        // Benchmark lazy evaluation with expression templates
        // Note: Current implementation may already partially optimize this
        auto start_lazy = high_resolution_clock::now();
        Tensor result_lazy;
        for (int i = 0; i < num_iterations; ++i) {
            result_lazy = (data * scalar).sigmoid(); // Should compose operations
        }
        cudaDeviceSynchronize();
        auto end_lazy = high_resolution_clock::now();
        double lazy_ms = duration_cast<microseconds>(end_lazy - start_lazy).count() / 1000.0 / num_iterations;

        // Verify correctness
        bool correctness_pass = result_eager.all_close(result_lazy, 1e-5, 1e-5);

        double speedup = eager_ms / lazy_ms;

        return {eager_ms, lazy_ms, speedup, correctness_pass, 1}; // 1 intermediate saved
    }

    // Benchmark: (x - mean) / std  - Normalization pattern
    BenchmarkResult benchmark_normalization(size_t n, int num_iterations = 100) {
        auto data = Tensor::rand({static_cast<int>(n)}, Device::CUDA);
        float mean = 0.5f;
        float std = 0.2f;

        // Warm-up
        for (int i = 0; i < 5; ++i) {
            auto result = (data - mean) / std;
            cudaDeviceSynchronize();
        }

        // Benchmark eager evaluation
        auto start_eager = high_resolution_clock::now();
        Tensor result_eager;
        for (int i = 0; i < num_iterations; ++i) {
            auto temp = data - mean;   // Intermediate 1
            result_eager = temp / std; // Result
        }
        cudaDeviceSynchronize();
        auto end_eager = high_resolution_clock::now();
        double eager_ms = duration_cast<microseconds>(end_eager - start_eager).count() / 1000.0 / num_iterations;

        // Benchmark lazy evaluation
        auto start_lazy = high_resolution_clock::now();
        Tensor result_lazy;
        for (int i = 0; i < num_iterations; ++i) {
            result_lazy = (data - mean) / std;
        }
        cudaDeviceSynchronize();
        auto end_lazy = high_resolution_clock::now();
        double lazy_ms = duration_cast<microseconds>(end_lazy - start_lazy).count() / 1000.0 / num_iterations;

        // Verify correctness
        bool correctness_pass = result_eager.all_close(result_lazy, 1e-5, 1e-5);

        double speedup = eager_ms / lazy_ms;

        return {eager_ms, lazy_ms, speedup, correctness_pass, 1};
    }

    // Benchmark: (x * w + b).relu()  - Affine + activation
    BenchmarkResult benchmark_affine_relu(size_t n, int num_iterations = 100) {
        auto data = Tensor::rand({static_cast<int>(n)}, Device::CUDA);
        float w = 2.5f;
        float b = 0.1f;

        // Warm-up
        for (int i = 0; i < 5; ++i) {
            auto result = (data * w + b).relu();
            cudaDeviceSynchronize();
        }

        // Benchmark eager evaluation
        auto start_eager = high_resolution_clock::now();
        Tensor result_eager;
        for (int i = 0; i < num_iterations; ++i) {
            auto temp1 = data * w;       // Intermediate 1
            auto temp2 = temp1 + b;      // Intermediate 2
            result_eager = temp2.relu(); // Result
        }
        cudaDeviceSynchronize();
        auto end_eager = high_resolution_clock::now();
        double eager_ms = duration_cast<microseconds>(end_eager - start_eager).count() / 1000.0 / num_iterations;

        // Benchmark lazy evaluation
        auto start_lazy = high_resolution_clock::now();
        Tensor result_lazy;
        for (int i = 0; i < num_iterations; ++i) {
            result_lazy = (data * w + b).relu();
        }
        cudaDeviceSynchronize();
        auto end_lazy = high_resolution_clock::now();
        double lazy_ms = duration_cast<microseconds>(end_lazy - start_lazy).count() / 1000.0 / num_iterations;

        // Verify correctness
        bool correctness_pass = result_eager.all_close(result_lazy, 1e-5, 1e-5);

        double speedup = eager_ms / lazy_ms;

        return {eager_ms, lazy_ms, speedup, correctness_pass, 2}; // 2 intermediates saved
    }

    // Benchmark: x.abs().sqrt()  - Chained unary operations
    BenchmarkResult benchmark_abs_sqrt(size_t n, int num_iterations = 100) {
        auto data = Tensor::randn({static_cast<int>(n)}, Device::CUDA); // Can have negative values

        // Warm-up
        for (int i = 0; i < 5; ++i) {
            auto result = data.abs().sqrt();
            cudaDeviceSynchronize();
        }

        // Benchmark eager evaluation
        auto start_eager = high_resolution_clock::now();
        Tensor result_eager;
        for (int i = 0; i < num_iterations; ++i) {
            auto temp = data.abs();     // Intermediate
            result_eager = temp.sqrt(); // Result
        }
        cudaDeviceSynchronize();
        auto end_eager = high_resolution_clock::now();
        double eager_ms = duration_cast<microseconds>(end_eager - start_eager).count() / 1000.0 / num_iterations;

        // Benchmark lazy evaluation (should use expression templates)
        auto start_lazy = high_resolution_clock::now();
        Tensor result_lazy;
        for (int i = 0; i < num_iterations; ++i) {
            result_lazy = data.abs().sqrt();
        }
        cudaDeviceSynchronize();
        auto end_lazy = high_resolution_clock::now();
        double lazy_ms = duration_cast<microseconds>(end_lazy - start_lazy).count() / 1000.0 / num_iterations;

        // Verify correctness
        bool correctness_pass = result_eager.all_close(result_lazy, 1e-5, 1e-5);

        double speedup = eager_ms / lazy_ms;

        return {eager_ms, lazy_ms, speedup, correctness_pass, 1};
    }
};

TEST_F(TransformIteratorBenchmarkTest, MulSigmoid_Small) {
    std::cout << "\n========================================================================================================\n";
    std::cout << "TRANSFORM ITERATOR BENCHMARK: (x * 2.0).sigmoid() - Small (10K elements)\n";
    std::cout << "========================================================================================================\n\n";

    auto result = benchmark_mul_sigmoid(10000, 1000);

    std::cout << std::fixed << std::setprecision(4);
    std::cout << "Eager evaluation (materialize):  " << result.eager_ms << " ms\n";
    std::cout << "Lazy evaluation (expression):    " << result.lazy_ms << " ms\n";
    std::cout << "Speedup:                         " << result.speedup << "x ";

    if (result.speedup >= 1.5) {
        std::cout << "✓ EXCELLENT\n";
    } else if (result.speedup >= 1.2) {
        std::cout << "✓ FASTER\n";
    } else if (result.speedup >= 1.0) {
        std::cout << "~ SIMILAR\n";
    } else {
        std::cout << "⚠ SLOWER\n";
    }

    std::cout << "Intermediates eliminated:        " << result.num_intermediates_saved << "\n";
    std::cout << "Correctness:                     " << (result.correctness_pass ? "✓ PASS" : "✗ FAIL") << "\n";

    EXPECT_TRUE(result.correctness_pass);
}

TEST_F(TransformIteratorBenchmarkTest, Normalization_Medium) {
    std::cout << "\n========================================================================================================\n";
    std::cout << "TRANSFORM ITERATOR BENCHMARK: (x - mean) / std - Medium (100K elements)\n";
    std::cout << "========================================================================================================\n\n";

    auto result = benchmark_normalization(100000, 100);

    std::cout << std::fixed << std::setprecision(4);
    std::cout << "Eager evaluation (materialize):  " << result.eager_ms << " ms\n";
    std::cout << "Lazy evaluation (expression):    " << result.lazy_ms << " ms\n";
    std::cout << "Speedup:                         " << result.speedup << "x ";

    if (result.speedup >= 1.5) {
        std::cout << "✓ EXCELLENT\n";
    } else if (result.speedup >= 1.2) {
        std::cout << "✓ FASTER\n";
    } else if (result.speedup >= 1.0) {
        std::cout << "~ SIMILAR\n";
    } else {
        std::cout << "⚠ SLOWER\n";
    }

    std::cout << "Intermediates eliminated:        " << result.num_intermediates_saved << "\n";
    std::cout << "Correctness:                     " << (result.correctness_pass ? "✓ PASS" : "✗ FAIL") << "\n";

    EXPECT_TRUE(result.correctness_pass);
}

TEST_F(TransformIteratorBenchmarkTest, AffineReLU_Medium) {
    std::cout << "\n========================================================================================================\n";
    std::cout << "TRANSFORM ITERATOR BENCHMARK: (x * w + b).relu() - Medium (100K elements)\n";
    std::cout << "========================================================================================================\n\n";

    auto result = benchmark_affine_relu(100000, 100);

    std::cout << std::fixed << std::setprecision(4);
    std::cout << "Eager evaluation (materialize):  " << result.eager_ms << " ms\n";
    std::cout << "Lazy evaluation (expression):    " << result.lazy_ms << " ms\n";
    std::cout << "Speedup:                         " << result.speedup << "x ";

    if (result.speedup >= 1.5) {
        std::cout << "✓ EXCELLENT\n";
    } else if (result.speedup >= 1.2) {
        std::cout << "✓ FASTER\n";
    } else if (result.speedup >= 1.0) {
        std::cout << "~ SIMILAR\n";
    } else {
        std::cout << "⚠ SLOWER\n";
    }

    std::cout << "Intermediates eliminated:        " << result.num_intermediates_saved << "\n";
    std::cout << "Correctness:                     " << (result.correctness_pass ? "✓ PASS" : "✗ FAIL") << "\n";

    EXPECT_TRUE(result.correctness_pass);
}

TEST_F(TransformIteratorBenchmarkTest, AbsSqrt_Large) {
    std::cout << "\n========================================================================================================\n";
    std::cout << "TRANSFORM ITERATOR BENCHMARK: x.abs().sqrt() - Large (1M elements)\n";
    std::cout << "========================================================================================================\n\n";

    auto result = benchmark_abs_sqrt(1000000, 100);

    std::cout << std::fixed << std::setprecision(4);
    std::cout << "Eager evaluation (materialize):  " << result.eager_ms << " ms\n";
    std::cout << "Lazy evaluation (expression):    " << result.lazy_ms << " ms\n";
    std::cout << "Speedup:                         " << result.speedup << "x ";

    if (result.speedup >= 1.5) {
        std::cout << "✓ EXCELLENT\n";
    } else if (result.speedup >= 1.2) {
        std::cout << "✓ FASTER\n";
    } else if (result.speedup >= 1.0) {
        std::cout << "~ SIMILAR\n";
    } else {
        std::cout << "⚠ SLOWER\n";
    }

    std::cout << "Intermediates eliminated:        " << result.num_intermediates_saved << "\n";
    std::cout << "Correctness:                     " << (result.correctness_pass ? "✓ PASS" : "✗ FAIL") << "\n";

    EXPECT_TRUE(result.correctness_pass);
}

TEST_F(TransformIteratorBenchmarkTest, Summary) {
    std::cout << "\n========================================================================================================\n";
    std::cout << "TRANSFORM ITERATOR BENCHMARK SUMMARY\n";
    std::cout << "========================================================================================================\n\n";

    std::cout << "KEY FINDINGS:\n\n";
    std::cout << "Transform iterators provide lazy evaluation by:\n";
    std::cout << "  1. Eliminating intermediate allocations\n";
    std::cout << "  2. Single kernel launch for chained operations\n";
    std::cout << "  3. Better memory bandwidth utilization\n";
    std::cout << "  4. Improved instruction-level parallelism\n\n";

    std::cout << "EXPECTED PERFORMANCE:\n\n";
    std::cout << "  - Simple chains (2 ops): 1.3-1.5× speedup vs eager\n";
    std::cout << "  - Complex chains (3+ ops): 1.5-2× speedup vs eager\n";
    std::cout << "  - Memory savings: N × sizeof(intermediate) per operation\n\n";

    std::cout << "USE CASES:\n\n";
    std::cout << "  - Image normalization: (img - mean) / std\n";
    std::cout << "  - Activation functions: (x * w + b).relu()\n";
    std::cout << "  - Data preprocessing: (x * scale).clamp(min, max)\n";
    std::cout << "  - Feature transforms: x.abs().sqrt().log()\n\n";

    std::cout << "IMPLEMENTATION STATUS:\n\n";
    std::cout << "  - Expression templates: ✓ Already implemented\n";
    std::cout << "  - Functor composition: ✓ Already implemented\n";
    std::cout << "  - Transform iterator: 🔜 To be added for zero-copy\n";
    std::cout << "  - Constant iterator: 🔜 To be added for scalar broadcasting\n\n";

    std::cout << "========================================================================================================\n";
}
